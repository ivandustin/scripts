#!/usr/bin/env python3
from sys import stdin, stdout
from os import environ
from transformers import AutoTokenizer, AutoModelForPreTraining
from numpy import savetxt
import torch


def main():
    model_name = environ.get("EMBEDDING_MODEL", "sentence-transformers/LaBSE")
    tokenizer = AutoTokenizer.from_pretrained(model_name)
    model = AutoModelForPreTraining.from_pretrained(model_name)
    model.eval()
    for line in stdin:
        text = line.strip()
        input_ids = tokenizer.encode(text, add_special_tokens=False)
        input_ids = torch.tensor(input_ids).unsqueeze(0)
        outputs = model(input_ids, output_hidden_states=True)
        final_hidden = outputs.hidden_states[-1]
        text_embedding = final_hidden.mean(dim=1)
        array = text_embedding.detach().numpy()
        savetxt(stdout, array)


if __name__ == "__main__":
    with torch.no_grad():
        main()
