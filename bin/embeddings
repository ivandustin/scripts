#!/usr/bin/env python3
from os import environ
from sys import argv, stdin
from functools import partial
from transformers import AutoModelForPreTraining
import torch
from numpystring import to_string
from batchline import get

IS_GPU = torch.cuda.is_available()


def main():
    index = int(argv[1]) if len(argv) > 1 else None
    model_name = environ.get("MODEL", "sentence-transformers/LaBSE")
    model = to_gpu(AutoModelForPreTraining.from_pretrained(model_name).eval())
    model = partial(model, output_hidden_states=True)
    for lines in get(stdin):
        input_ids = map(to_gpu, map(unshift, map(torch.tensor, map(parse, lines))))
        embeddings = map(get_embeddings, map(model, input_ids))
        if index is not None:
            embeddings = map(partial(select, index), embeddings)
        outputs = list(map(shift, embeddings))
        for output in map(to_string, map(to_cpu, outputs)):
            print(output)


def parse(line):
    return list(map(int, line.split(" ")))


def to_gpu(tensor):
    return tensor.cuda() if IS_GPU else tensor


def to_cpu(tensor):
    return tensor.detach().cpu().numpy()


def get_embeddings(output):
    return output.hidden_states[-1]


def select(index, embeddings):
    return embeddings[:, index, :].unsqueeze(1)


def shift(tensor):
    return tensor.squeeze(0)


def unshift(tensor):
    return tensor.unsqueeze(0)


if __name__ == "__main__":
    with torch.no_grad():
        main()
