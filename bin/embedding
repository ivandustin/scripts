#!/usr/bin/env python3
from sys import stdin, stdout
from os import environ
from transformers import AutoModelForPreTraining
from numpy import fromstring, savetxt
import torch

IS_GPU = torch.cuda.is_available()


def main():
    model_name = environ.get("MODEL", "sentence-transformers/LaBSE")
    model = cuda(AutoModelForPreTraining.from_pretrained(model_name).eval())
    for line in stdin:
        tokens = fromstring(line.strip(), sep=" ", dtype=int)
        tokens = torch.tensor(tokens).unsqueeze(0)
        outputs = model(cuda(tokens), output_hidden_states=True)
        final_hidden = outputs.hidden_states[-1]
        cls_embedding = final_hidden[:, 0]
        savetxt(stdout, cls_embedding.cpu().detach().numpy())


def cuda(tensor):
    return tensor.cuda() if IS_GPU else tensor


if __name__ == "__main__":
    with torch.no_grad():
        main()
