#!/usr/bin/env python3
from base64 import b64encode
from io import BytesIO
from os import environ
from sys import stdin
from transformers import AutoModelForPreTraining
from numpy import fromstring, save
import torch

IS_GPU = torch.cuda.is_available()


def main():
    model_name = environ.get("MODEL", "sentence-transformers/LaBSE")
    model = cuda(AutoModelForPreTraining.from_pretrained(model_name).eval())
    for line in stdin:
        tokens = fromstring(line.strip(), sep=" ", dtype=int)
        tokens = torch.tensor(tokens).unsqueeze(0)
        outputs = model(cuda(tokens), output_hidden_states=True)
        embeddings = outputs.hidden_states[-1].squeeze(0)
        array = embeddings.detach().cpu().numpy()
        print(to_string(array))


def cuda(tensor):
    return tensor.cuda() if IS_GPU else tensor


def to_string(array):
    buffer = BytesIO()
    save(buffer, array)
    return b64encode(buffer.getvalue()).decode("utf-8")


if __name__ == "__main__":
    with torch.no_grad():
        main()
